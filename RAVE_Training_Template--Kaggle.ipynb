{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAVE\n",
    "**RAVE** is a variational autoencoder for fast and high-quality neural audio synthesis by Antoine Caillon and Philippe Esling.\n",
    "\\\n",
    "\\\n",
    "[Article on arxiv](https://arxiv.org/abs/2111.05011) & [Source code on Github](https://github.com/acids-ircam/RAVE)\n",
    "\n",
    "----\n",
    "\n",
    "Notebook Author: [Martin Heinze](https://github.com/devstermarts) \n",
    "\n",
    "Date: 24.10.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Conda, RAVE, dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Conda\n",
    "!mkdir /kaggle/temp\n",
    "%cd /kaggle/temp\n",
    "!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh -o miniconda.sh\n",
    "!chmod +x miniconda.sh\n",
    "!sh miniconda.sh -b -p /kaggle/temp/miniconda\n",
    "\n",
    "#Upgrade ipython ipykernel, install ffmpeg\n",
    "!/kaggle/temp/miniconda/bin/pip install --upgrade ipython ipykernel\n",
    "!/kaggle/temp/miniconda/bin/conda install ffmpeg --yes\n",
    "\n",
    "#Install RAVE\n",
    "#Pin to specific release tag if necessary using 'acids-rave==tag.versionâ€˜\n",
    "!/kaggle/temp/miniconda/bin/pip install acids-rave==2.2.2\n",
    "\n",
    "#Uninstall Cublas library. For some reason this has created conflicts with the environment on Kaggle in the past. \n",
    "!/kaggle/temp/miniconda/bin/pip uninstall nvidia_cublas_cu11 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset\n",
    "\n",
    "Preprocessing is necessary once per training dataset. In below section, the data from preprocessing is stored in '/kaggle/working/processed'. Use the filepath to your dataset as input path, this is usually '/kaggle/input/your_audio_dataset'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess dataset\n",
    "!mkdir /kaggle/working/processed\n",
    "!/kaggle/temp/miniconda/bin/rave preprocess \\\n",
    "--input_path /kaggle/input/your_audio_dataset/ \\\n",
    "--output_path /kaggle/working/processed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start initial training\n",
    "\n",
    "While training the output is stored in a folder named 'your_training_name' followed by an underscore and a 10-character-string inside '/kaggle/working/runs'. '/kaggle/working/' also contains a 'status' folder with 'data.mdb' and 'lock.mdb' files.\n",
    "\n",
    "***For initial training, the below section has been enabled, disable when you want to resume your training.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate training\n",
    "#Use config parameters as preferred for your training. \n",
    "#The setup below is exemplary. \n",
    "#For configuration options check https://github.com/acids-ircam/RAVE#training\n",
    "#Other training parameters can be customized using --override, check train.py \n",
    "\n",
    "%cd /kaggle/working\n",
    "!/kaggle/temp/miniconda/bin/rave train \\\n",
    "--config v2.gin \\\n",
    "--config wasserstein \\\n",
    "--db_path /kaggle/working/processed/ \\\n",
    "--name your_training_name \\\n",
    "--override CAPACITY=128 \\\n",
    "--override PHASE_1_DURATION=2000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume training\n",
    "In order to conveniently resume training RAVE on Kaggle, you can transform the output data of the first run into a new dataset from the output tab of your notebook. You then add the new dataset to the notebook, disable the above initial, **Preprocess** and **Training** sections of the notebook and adjust the below section according to your initial training details.\n",
    "To further progress on the training after the first run, update the processed dataset by creating a new version from the output of the latest run. Make sure to check for updates on the dataset in your notebook before resuming the training.\n",
    "\n",
    "***For initial training, the below section has been disabled, enable when you want to resume your training and disable the initial training section before running the notebook.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Copy contents of earlier training to /kaggle/working folder.\n",
    "#!cp -r /kaggle/input/root_folder_of_your_earlier_training/* /kaggle/working\n",
    "\n",
    "#%cd /kaggle/working/\n",
    "\n",
    "##Resume training\n",
    "##Use config parameters as used in your earlier training.\n",
    "#!/kaggle/temp/miniconda/bin/rave train \\\n",
    "#--config v2.gin \\\n",
    "#--config wasserstein \\\n",
    "#--db_path /kaggle/working/processed/ \\\n",
    "#--name your_training_name \\\n",
    "#--override CAPACITY=128 \\\n",
    "#--override PHASE_1_DURATION=2000000 \\\n",
    "#--ckpt /kaggle/working/runs/your_training_name_with_a_random_string_in_the_end/version_X/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model\n",
    "After your training is finished, you can export a model (.ts Torchscript) file.\n",
    "\\\n",
    "\\\n",
    "***The below section has been disabled. The training won't be finished automatically, you would have to run model export manually, either via this notebook or locally on your machine. If the latter, make sure the setup is the same (e.g. RAVE version, dependencies, libraries...).*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model export. \n",
    "##Use '--streaming' flag to export a model capable of real time processing.\n",
    "##Use '--stereo' for a model with two decoders.\n",
    "\n",
    "##Copy contents of earlier training to /kaggle/working folder.\n",
    "#!cp -r /kaggle/input/root_folder_of_your_earlier_training/* /kaggle/working\n",
    "\n",
    "##Export model\n",
    "#!/kaggle/temp/miniconda/bin/rave export \\\n",
    "#--run /kaggle/working/runs/your_training_name_with_a_random_string_in_the_end \\\n",
    "#--streaming \\\n",
    "#--stereo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip: download your Kaggle Data\n",
    "The Kaggle API allows downloading your training data from your notebooks conveniently. You can find information on setup and CLI commands here: https://github.com/Kaggle/kaggle-api"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
