{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSCHAOS2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VSCHAOS2** is a vintage-flavoured neural audio synthesis package created by [Axel Chemla Romeu Santos](https://github.com/domkirke). It is based on unsupervised / (semi-)supervised training of spectral information using variational auto-encoders. vschaos2 may be trained on small batches of data, is very light, usable using small architectures, and can also be used for auxiliary predictive tasks.\n",
    "\n",
    "[Axel's PhD Thesis](https://hal.archives-ouvertes.fr/tel-03543235) & [Source code on Github](https://github.com/acids-ircam/vschaos2/)\n",
    "\n",
    "----\n",
    "\n",
    "Notebook author: [Martin Heinze](https://github.com/devstermarts)\n",
    "\n",
    "Last updated: 21.12.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Miniconda, VSCHAOS2, dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Miniconda\n",
    "!mkdir /kaggle/temp/\n",
    "%cd /kaggle/temp\n",
    "!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh -o miniconda.sh\n",
    "!chmod +x miniconda.sh\n",
    "!sh miniconda.sh -b -p /kaggle/temp/miniconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install VSCHAOS2 either from original repo or fork (default)\n",
    "#!git clone https://github.com/acids-ircam/vschaos2\n",
    "!git clone https://github.com/devstermarts/vschaos2\n",
    "#In case your training gets stuck in validation/ reconstruction, check out the wip branch of the fork instead:\n",
    "#!git clone -b wip https://github.com/devstermarts/vschaos2\n",
    "\n",
    "%cd /kaggle/temp/vschaos2\n",
    "\n",
    "#Install dependencies (extracted from original requirements.txt, which seems to contain faulty information)\n",
    "!/kaggle/temp/miniconda/bin/pip install tqdm dill numpy>=1.21 matplotlib>=3.5 scipy>=1.7 scikit_learn>=1.0 termcolor GPUtil soundfile torchcrepe tensorboard pytorch_lightning==1.6 hydra-core==1.2 cached-conv>=2.5.0 \n",
    "!/kaggle/temp/miniconda/bin/pip install git+https://github.com/domkirke/acids_transforms.git \n",
    "!/kaggle/temp/miniconda/bin/pip install git+https://github.com/domkirke/lardon.git\n",
    "!/kaggle/temp/miniconda/bin/pip install git+https://github.com/acids-ircam/nn_tilde.git@feature/attributes\n",
    "\n",
    "#Force reinstall of working PyTorch and NumPy versions. \n",
    "#!/kaggle/temp/miniconda/bin/pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --force-reinstall\n",
    "!/kaggle/temp/miniconda/bin/pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --force-reinstall\n",
    "!/kaggle/temp/miniconda/bin/pip install numpy==1.23 --force-reinstall\n",
    "\n",
    "#Upgrade ipython ipykernel\n",
    "!/kaggle/temp/miniconda/bin/pip install --upgrade ipython ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "Import your audio files as Kaggle dataset. For preprocessing, these files need to be copied to the runtime's working folder. Adjust the path to your dataset ('/kaggle/input/your_audio_dataset') accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup folders and copy files\n",
    "!mkdir /kaggle/working/train\n",
    "!mkdir /kaggle/working/train/data\n",
    "!cp -r /kaggle/input/your_audio_dataset/* /kaggle/working/train/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training\n",
    "First you need to specify a name for the training (flag 'name'). \n",
    "The directory to run the training/ save the training data ('rundir') and the path to the training data root folder (specified after '+data.dataset.root') can be left as is in the section below.\n",
    "The '--config-name' flag can set either to 'dgt_mag_precise' or 'dgt_mag_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start training\n",
    "%cd /kaggle/working/train/\n",
    "!/kaggle/temp/miniconda/bin/python /kaggle/temp/vschaos2/train.py \\\n",
    "--config-name dgt_mag_precise \\\n",
    "name=your_training_name \\\n",
    "rundir=\"/kaggle/working/train\" +data.dataset.root=\"/kaggle/working/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "To export a model after training, you first need to create a new Kaggle dataset from your training output.\n",
    "Import this new dataset to the notebook and adjust the filepath below to the 'your_training_name' subfolder in your 'rundir'. The output is stored to the root of the working folder.\n",
    "\n",
    "***For the export, start a notebook session (don't save and run this notebook). In the session, make sure to run the setup cells for Miniconda and VSCHAOS2 and dependencies install before running export.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model export\n",
    "!/kaggle/temp/miniconda/bin/python3 /kaggle/temp/vschaos2/script.py \\\n",
    "/kaggle/input/train/your_training_name -o /kaggle/working"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
