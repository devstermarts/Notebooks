{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VSCHAOS2\n\n**VSCHAOS2** is a vintage-flavoured neural audio synthesis package created by [Axel Chemla Romeu Santos](https://github.com/domkirke). It is based on unsupervised / (semi-)supervised training of spectral information using variational auto-encoders. vschaos2 may be trained on small batches of data, is very light, usable using small architectures, and can also be used for auxiliary predictive tasks.\n\n[Axel's PhD Thesis](https://hal.archives-ouvertes.fr/tel-03543235) & [Source code on Github](https://github.com/acids-ircam/vschaos2/)\n\n----\n\nNotebook Author: [Martin Heinze](https://github.com/devstermarts)\nDate: 23.11.2024","metadata":{}},{"cell_type":"markdown","source":"## Setup runtime: Miniconda, VSCHAOS2, dependencies","metadata":{}},{"cell_type":"code","source":"#Install Miniconda\n!mkdir /kaggle/temp/\n%cd /kaggle/temp\n!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh -o miniconda.sh\n!chmod +x miniconda.sh\n!sh miniconda.sh -b -p /kaggle/temp/miniconda","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Install VSCHAOS2 either from original repo or fork (default)\n#!git clone https://github.com/acids-ircam/vschaos2\n!git clone https://github.com/devstermarts/vschaos2\n#In case your training gets stuck in validation/ reconstruction, check out the wip branch of the fork.\n%cd /kaggle/temp/vschaos2\n\n#Install dependencies (extracted from original requirements.txt, which seems to contain faulty information)\n!/kaggle/temp/miniconda/bin/pip install tqdm dill numpy>=1.21 matplotlib>=3.5 scipy>=1.7 scikit_learn>=1.0 termcolor GPUtil soundfile torchcrepe tensorboard pytorch_lightning==1.6 hydra-core==1.2 cached-conv>=2.5.0 \n!/kaggle/temp/miniconda/bin/pip install git+https://github.com/domkirke/acids_transforms.git \n!/kaggle/temp/miniconda/bin/pip install git+https://github.com/domkirke/lardon.git\n!/kaggle/temp/miniconda/bin/pip install git+https://github.com/acids-ircam/nn_tilde.git@feature/attributes\n\n#Force reinstall of working PyTorch and NumPy versions. \n!/kaggle/temp/miniconda/bin/pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --force-reinstall\n!/kaggle/temp/miniconda/bin/pip install numpy==1.23 --force-reinstall\n\n#Optional upgrade ipython ipykernel\n#!/kaggle/temp/miniconda/bin/pip install --upgrade ipython ipykernel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import dataset\nImport your audio files as Kaggle dataset. For pre processing, these files need to be copied to the runtime's working folder. Adjust the path to your dataset ('/kaggle/input/your_audio_dataset') accordingly. ","metadata":{}},{"cell_type":"code","source":"#Setup folders and copy files\n!mkdir /kaggle/working/train\n!mkdir /kaggle/working/train/data\n!cp -r /kaggle/input/your_audio_dataset/* /kaggle/working/train/data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Start training.\nFirst you need to specify a name for the training (flag 'name'). \nThe directory to run the training/ save the training data ('rundir') and the path to the training data root folder (specified after '+data.dataset.root') can be left as is in the section below.\nThe '--config-name' flag can set either to 'dgt_mag_precise' or 'dgt_mag_normal'","metadata":{}},{"cell_type":"code","source":"#Start training\n%cd /kaggle/working/train/\n!/kaggle/temp/miniconda/bin/python /kaggle/temp/vschaos2/train.py \\\n--config-name dgt_mag_precise \\\nname=your_training_name \\\nrundir=\"/kaggle/working/train\" +data.dataset.root=\"/kaggle/working/train/\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Export\nTo export a model after training, you first need to create a new Kaggle dataset from your training output.\nImport this new dataset to the notebook and adjust the filepath below to the 'your_training_name' subfolder in your 'rundir'. The output is stored to the root of the working folder.\n\n***For the export, start a notebook session (don't save and run this notebook). In the session, make sure to run the setup cells for Miniconda and VSCHAOS2 and dependencies install before running export.***","metadata":{}},{"cell_type":"code","source":"#Model export\n!/kaggle/temp/miniconda/bin/python3 /kaggle/temp/vschaos2/script.py \\\n/kaggle/input/train/your_training_name -o /kaggle/working","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
